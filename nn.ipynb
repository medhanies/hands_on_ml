{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a perceptron network\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "iris = load_iris(as_frame=True)\n",
    "X = iris.data[[\"petal length (cm)\", \"petal width (cm)\"]].values\n",
    "y = (iris.target == 0) # Iris setosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Perceptron(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Perceptron</label><div class=\"sk-toggleable__content\"><pre>Perceptron(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Perceptron(random_state=42)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "per_clf = Perceptron(random_state=42)\n",
    "per_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict new values\n",
    "X_new = [[2, 0.5], [3, 1]]\n",
    "y_pred = per_clf.predict(X_new) # predicts True and False for these 2 flowers\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a nn with 3 hidden layers with 50 neurons each\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "mlp_reg = MLPRegressor(hidden_layer_sizes=[50, 50, 50], random_state=42)\n",
    "pipeline = make_pipeline(StandardScaler(), mlp_reg)\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_valid)\n",
    "rmse = mean_squared_error(y_valid, y_pred, squared=False) # about 0.505"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using keras load fashion mnist data\n",
    "import tensorflow as tf\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\n",
    "X_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\n",
    "X_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale pixel intensities\n",
    "X_train, X_valid, X_test = X_train / 255., X_valid / 255., X_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model 2 hidden layers and with 10 output classes\n",
    "tf.random.set_seed(42)\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape=[28, 28]))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(300, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers\n",
    "model.layers[1].name == 'dense'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases = model.layers[1].get_weights()\n",
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model with loss function and optimizer\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show learning curves of loss, optimizers and metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(\n",
    "    figsize=(8, 5), xlim=[0, 29], ylim=[0, 1], grid=True, xlabel=\"Epoch\",\n",
    "    style=[\"r--\", \"g--.\", \"b-\", \"b-*\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate how well model does on test set\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes with highest probability\n",
    "import numpy as np\n",
    "\n",
    "y_pred = y_proba.argmax(axis=-1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_new = y_test[:3]\n",
    "y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build regression MLP NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build NN for regression\n",
    "tf.random.set_seed(42)\n",
    "norm_layer = tf.keras.layers.Normalization(input_shape=X_train.shape[1:])\n",
    "model = tf.keras.Sequential([\n",
    "    norm_layer,\n",
    "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"RootMeanSquaredError\"])\n",
    "norm_layer.adapt(X_train)\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "mse_test, rmse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functional Model Wide and Deep NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Normalization()\n",
    "hidden_layer1 = tf.keras.layers.Dense(30, activation=\"relu\")\n",
    "hidden_layer2 = tf.keras.layers.Dense(30, activation=\"relu\")\n",
    "concat_layer = tf.keras.layers.Concatenate()\n",
    "output_layer = tf.keras.layers.Dense(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = tf.keras.layers.Input(shape=X_train.shape[1:])\n",
    "normalized = normalization_layer(input_)\n",
    "hidden1 = hidden_layer1(normalized)\n",
    "hidden2 = hidden_layer2(hidden1)\n",
    "concat = concat_layer([normalized, hidden2])\n",
    "output = output_layer(concat)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 inputs 2 different paths\n",
    "input_wide = tf.keras.layers.Input(shape=[5]) # features 0 to 4\n",
    "input_deep = tf.keras.layers.Input(shape=[6]) ## features 2 to 7\n",
    "norm_layer_wide = tf.keras.layers.Normalization()\n",
    "norm_layer_deep = tf.keras.layers.Normalization()\n",
    "\n",
    "norm_wide = norm_layer_wide(input_wide)\n",
    "norm_deep = norm_layer_deep(input_deep)\n",
    "hidden1 = tf.keras.layers.Dense(30, activation=\"relu\")(norm_deep)\n",
    "hidden2 = tf.keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = tf.keras.layers.concatenate([norm_wide, hidden2])\n",
    "output = tf.keras.layers.Dense(1)(concat)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_wide, input_deep], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 810us/step - loss: 0.4218 - root_mean_squared_error: 0.6495 - val_loss: 0.4043 - val_root_mean_squared_error: 0.6358\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 537us/step - loss: 0.3893 - root_mean_squared_error: 0.6239 - val_loss: 1.1397 - val_root_mean_squared_error: 1.0676\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 726us/step - loss: 0.3859 - root_mean_squared_error: 0.6212 - val_loss: 6.3081 - val_root_mean_squared_error: 2.5116\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 508us/step - loss: 0.3940 - root_mean_squared_error: 0.6277 - val_loss: 7.3957 - val_root_mean_squared_error: 2.7195\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 494us/step - loss: 0.4124 - root_mean_squared_error: 0.6422 - val_loss: 2.2125 - val_root_mean_squared_error: 1.4874\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 509us/step - loss: 0.3600 - root_mean_squared_error: 0.6000 - val_loss: 1.9858 - val_root_mean_squared_error: 1.4092\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 596us/step - loss: 0.3596 - root_mean_squared_error: 0.5997 - val_loss: 2.5368 - val_root_mean_squared_error: 1.5927\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 570us/step - loss: 0.3580 - root_mean_squared_error: 0.5983 - val_loss: 3.3804 - val_root_mean_squared_error: 1.8386\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 510us/step - loss: 0.3736 - root_mean_squared_error: 0.6112 - val_loss: 1.5664 - val_root_mean_squared_error: 1.2516\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 511us/step - loss: 0.3468 - root_mean_squared_error: 0.5889 - val_loss: 1.0202 - val_root_mean_squared_error: 1.0100\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 515us/step - loss: 0.3429 - root_mean_squared_error: 0.5856 - val_loss: 0.7952 - val_root_mean_squared_error: 0.8917\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 515us/step - loss: 0.3375 - root_mean_squared_error: 0.5809 - val_loss: 0.9562 - val_root_mean_squared_error: 0.9779\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 548us/step - loss: 0.3365 - root_mean_squared_error: 0.5801 - val_loss: 1.3675 - val_root_mean_squared_error: 1.1694\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 509us/step - loss: 0.3355 - root_mean_squared_error: 0.5792 - val_loss: 1.6377 - val_root_mean_squared_error: 1.2797\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 504us/step - loss: 0.3476 - root_mean_squared_error: 0.5896 - val_loss: 1.4554 - val_root_mean_squared_error: 1.2064\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 509us/step - loss: 0.3360 - root_mean_squared_error: 0.5797 - val_loss: 1.0890 - val_root_mean_squared_error: 1.0436\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 510us/step - loss: 0.3329 - root_mean_squared_error: 0.5770 - val_loss: 2.5208 - val_root_mean_squared_error: 1.5877\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 596us/step - loss: 0.3446 - root_mean_squared_error: 0.5871 - val_loss: 2.4431 - val_root_mean_squared_error: 1.5631\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 509us/step - loss: 0.3356 - root_mean_squared_error: 0.5793 - val_loss: 0.4852 - val_root_mean_squared_error: 0.6965\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 644us/step - loss: 0.3230 - root_mean_squared_error: 0.5683 - val_loss: 0.4081 - val_root_mean_squared_error: 0.6388\n",
      "162/162 [==============================] - 0s 303us/step - loss: 0.3188 - root_mean_squared_error: 0.5647\n",
      "1/1 [==============================] - 0s 46ms/step\n"
     ]
    }
   ],
   "source": [
    "# compile build train model\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=1e-3)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"RootMeanSquaredError\"])\n",
    "\n",
    "X_train_wide, X_train_deep = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_wide, X_valid_deep = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_wide, X_test_deep = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_wide, X_new_deep = X_test_wide[:3], X_test_deep[:3]\n",
    "\n",
    "norm_layer_wide.adapt(X_train_wide)\n",
    "norm_layer_deep.adapt(X_train_deep)\n",
    "history = model.fit((X_train_wide, X_train_deep), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_wide, X_valid_deep), y_valid))\n",
    "mse_test = model.evaluate((X_test_wide, X_test_deep), y_test)\n",
    "y_pred = model.predict((X_new_wide, X_new_deep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple outputs, aux output for regularization\n",
    "output = tf.keras.layers.Dense(1)(concat)\n",
    "aux_output = tf.keras.layers.Dense(1)(hidden2)\n",
    "model = tf.keras.Model(inputs=[input_wide, input_deep], outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each output needs own loss function\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=1e-3)\n",
    "model.compile(loss=(\"mse\", \"mse\"), loss_weights=(0.9, 0.1), optimizer=optimizer,\n",
    "              metrics=[\"RootMeanSquaredError\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 883us/step - loss: 0.8469 - dense_6_loss: 0.7534 - dense_7_loss: 1.6886 - dense_6_root_mean_squared_error: 0.8680 - dense_7_root_mean_squared_error: 1.2995 - val_loss: 0.5361 - val_dense_6_loss: 0.4699 - val_dense_7_loss: 1.1319 - val_dense_6_root_mean_squared_error: 0.6855 - val_dense_7_root_mean_squared_error: 1.0639\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 669us/step - loss: 0.3967 - dense_6_loss: 0.3802 - dense_7_loss: 0.5454 - dense_6_root_mean_squared_error: 0.6166 - dense_7_root_mean_squared_error: 0.7385 - val_loss: 0.5716 - val_dense_6_loss: 0.5660 - val_dense_7_loss: 0.6225 - val_dense_6_root_mean_squared_error: 0.7523 - val_dense_7_root_mean_squared_error: 0.7890\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 640us/step - loss: 0.3695 - dense_6_loss: 0.3576 - dense_7_loss: 0.4765 - dense_6_root_mean_squared_error: 0.5980 - dense_7_root_mean_squared_error: 0.6903 - val_loss: 0.3419 - val_dense_6_loss: 0.3295 - val_dense_7_loss: 0.4530 - val_dense_6_root_mean_squared_error: 0.5740 - val_dense_7_root_mean_squared_error: 0.6731\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 628us/step - loss: 0.3564 - dense_6_loss: 0.3461 - dense_7_loss: 0.4496 - dense_6_root_mean_squared_error: 0.5883 - dense_7_root_mean_squared_error: 0.6705 - val_loss: 0.5217 - val_dense_6_loss: 0.5111 - val_dense_7_loss: 0.6165 - val_dense_6_root_mean_squared_error: 0.7149 - val_dense_7_root_mean_squared_error: 0.7851\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 931us/step - loss: 0.3503 - dense_6_loss: 0.3413 - dense_7_loss: 0.4313 - dense_6_root_mean_squared_error: 0.5842 - dense_7_root_mean_squared_error: 0.6568 - val_loss: 0.3687 - val_dense_6_loss: 0.3599 - val_dense_7_loss: 0.4477 - val_dense_6_root_mean_squared_error: 0.5999 - val_dense_7_root_mean_squared_error: 0.6691\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 628us/step - loss: 0.3405 - dense_6_loss: 0.3318 - dense_7_loss: 0.4192 - dense_6_root_mean_squared_error: 0.5760 - dense_7_root_mean_squared_error: 0.6475 - val_loss: 0.6320 - val_dense_6_loss: 0.6393 - val_dense_7_loss: 0.5657 - val_dense_6_root_mean_squared_error: 0.7996 - val_dense_7_root_mean_squared_error: 0.7522\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 629us/step - loss: 0.3384 - dense_6_loss: 0.3303 - dense_7_loss: 0.4118 - dense_6_root_mean_squared_error: 0.5747 - dense_7_root_mean_squared_error: 0.6417 - val_loss: 1.4082 - val_dense_6_loss: 1.5044 - val_dense_7_loss: 0.5421 - val_dense_6_root_mean_squared_error: 1.2265 - val_dense_7_root_mean_squared_error: 0.7363\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 741us/step - loss: 0.3408 - dense_6_loss: 0.3336 - dense_7_loss: 0.4058 - dense_6_root_mean_squared_error: 0.5775 - dense_7_root_mean_squared_error: 0.6370 - val_loss: 3.0483 - val_dense_6_loss: 3.2471 - val_dense_7_loss: 1.2586 - val_dense_6_root_mean_squared_error: 1.8020 - val_dense_7_root_mean_squared_error: 1.1219\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 931us/step - loss: 0.3418 - dense_6_loss: 0.3352 - dense_7_loss: 0.4005 - dense_6_root_mean_squared_error: 0.5790 - dense_7_root_mean_squared_error: 0.6329 - val_loss: 0.7318 - val_dense_6_loss: 0.7662 - val_dense_7_loss: 0.4226 - val_dense_6_root_mean_squared_error: 0.8753 - val_dense_7_root_mean_squared_error: 0.6500\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 634us/step - loss: 0.3550 - dense_6_loss: 0.3502 - dense_7_loss: 0.3986 - dense_6_root_mean_squared_error: 0.5917 - dense_7_root_mean_squared_error: 0.6314 - val_loss: 1.0290 - val_dense_6_loss: 1.0612 - val_dense_7_loss: 0.7392 - val_dense_6_root_mean_squared_error: 1.0302 - val_dense_7_root_mean_squared_error: 0.8598\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 639us/step - loss: 0.3310 - dense_6_loss: 0.3246 - dense_7_loss: 0.3888 - dense_6_root_mean_squared_error: 0.5697 - dense_7_root_mean_squared_error: 0.6236 - val_loss: 0.3218 - val_dense_6_loss: 0.3145 - val_dense_7_loss: 0.3873 - val_dense_6_root_mean_squared_error: 0.5608 - val_dense_7_root_mean_squared_error: 0.6223\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 626us/step - loss: 0.3271 - dense_6_loss: 0.3206 - dense_7_loss: 0.3856 - dense_6_root_mean_squared_error: 0.5662 - dense_7_root_mean_squared_error: 0.6210 - val_loss: 0.3629 - val_dense_6_loss: 0.3529 - val_dense_7_loss: 0.4533 - val_dense_6_root_mean_squared_error: 0.5940 - val_dense_7_root_mean_squared_error: 0.6733\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 631us/step - loss: 0.3241 - dense_6_loss: 0.3178 - dense_7_loss: 0.3803 - dense_6_root_mean_squared_error: 0.5638 - dense_7_root_mean_squared_error: 0.6167 - val_loss: 0.3399 - val_dense_6_loss: 0.3256 - val_dense_7_loss: 0.4688 - val_dense_6_root_mean_squared_error: 0.5706 - val_dense_7_root_mean_squared_error: 0.6847\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 631us/step - loss: 0.3235 - dense_6_loss: 0.3173 - dense_7_loss: 0.3795 - dense_6_root_mean_squared_error: 0.5633 - dense_7_root_mean_squared_error: 0.6160 - val_loss: 0.3430 - val_dense_6_loss: 0.3321 - val_dense_7_loss: 0.4404 - val_dense_6_root_mean_squared_error: 0.5763 - val_dense_7_root_mean_squared_error: 0.6636\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 736us/step - loss: 0.3236 - dense_6_loss: 0.3177 - dense_7_loss: 0.3770 - dense_6_root_mean_squared_error: 0.5636 - dense_7_root_mean_squared_error: 0.6140 - val_loss: 0.3126 - val_dense_6_loss: 0.3051 - val_dense_7_loss: 0.3808 - val_dense_6_root_mean_squared_error: 0.5523 - val_dense_7_root_mean_squared_error: 0.6171\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 695us/step - loss: 0.3218 - dense_6_loss: 0.3159 - dense_7_loss: 0.3751 - dense_6_root_mean_squared_error: 0.5621 - dense_7_root_mean_squared_error: 0.6124 - val_loss: 0.3047 - val_dense_6_loss: 0.2965 - val_dense_7_loss: 0.3783 - val_dense_6_root_mean_squared_error: 0.5445 - val_dense_7_root_mean_squared_error: 0.6150\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 633us/step - loss: 0.3206 - dense_6_loss: 0.3149 - dense_7_loss: 0.3722 - dense_6_root_mean_squared_error: 0.5611 - dense_7_root_mean_squared_error: 0.6101 - val_loss: 0.5482 - val_dense_6_loss: 0.5360 - val_dense_7_loss: 0.6578 - val_dense_6_root_mean_squared_error: 0.7321 - val_dense_7_root_mean_squared_error: 0.8110\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 616us/step - loss: 0.3188 - dense_6_loss: 0.3130 - dense_7_loss: 0.3710 - dense_6_root_mean_squared_error: 0.5594 - dense_7_root_mean_squared_error: 0.6091 - val_loss: 0.6866 - val_dense_6_loss: 0.7092 - val_dense_7_loss: 0.4836 - val_dense_6_root_mean_squared_error: 0.8421 - val_dense_7_root_mean_squared_error: 0.6954\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 623us/step - loss: 0.3239 - dense_6_loss: 0.3185 - dense_7_loss: 0.3720 - dense_6_root_mean_squared_error: 0.5644 - dense_7_root_mean_squared_error: 0.6099 - val_loss: 1.3565 - val_dense_6_loss: 1.3864 - val_dense_7_loss: 1.0882 - val_dense_6_root_mean_squared_error: 1.1774 - val_dense_7_root_mean_squared_error: 1.0432\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 617us/step - loss: 0.3244 - dense_6_loss: 0.3193 - dense_7_loss: 0.3701 - dense_6_root_mean_squared_error: 0.5651 - dense_7_root_mean_squared_error: 0.6083 - val_loss: 0.5293 - val_dense_6_loss: 0.5423 - val_dense_7_loss: 0.4117 - val_dense_6_root_mean_squared_error: 0.7364 - val_dense_7_root_mean_squared_error: 0.6416\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "norm_layer_wide.adapt(X_train_wide)\n",
    "norm_layer_deep.adapt(X_train_deep)\n",
    "history = model.fit(\n",
    "    (X_train_wide, X_train_deep), (y_train, y_train), epochs=20,\n",
    "    validation_data=((X_valid_wide, X_valid_deep), (y_valid, y_valid))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 436us/step - loss: 0.3193 - dense_6_loss: 0.3134 - dense_7_loss: 0.3722 - dense_6_root_mean_squared_error: 0.5598 - dense_7_root_mean_squared_error: 0.6101\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "eval_results = model.evaluate((X_test_wide, X_test_deep), (y_test, y_test))\n",
    "weighted_sum_of_losses, main_loss, aux_loss, main_rmse, aux_rmse = eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 83ms/step\n"
     ]
    }
   ],
   "source": [
    "# predictions for each output\n",
    "y_pred_main, y_pred_aux = model.predict((X_new_wide, X_new_deep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.44477814],\n",
       "       [1.2067366 ],\n",
       "       [3.6383715 ]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
